"""
Gerador de conte√∫do gramatical usando IA - LangChain 0.3.
Implementa estrat√©gias GRAMMAR 1 (Sistem√°tica) e GRAMMAR 2 (Preven√ß√£o L1‚ÜíL2).
CORRIGIDO: Prompts contextuais via IA, integra√ß√£o com sistema IVO V2.
"""
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
import json
import asyncio
from dataclasses import dataclass

# YAML import
import yaml

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

# Pydantic 2 nativo - sem necessidade de compatibilidade
from pydantic import BaseModel, ValidationError, Field, ConfigDict

# Imports internos
from config.logging import get_logger
from config.models import get_openai_config, load_model_configs

# Logger configurado
logger = get_logger("grammar_generator")
logger.info("üöÄ Usando LangChain 0.3 com Pydantic 2 nativo + IA contextual")


# =============================================================================
# CONSTANTES T√âCNICAS (MANTIDAS - PADR√ïES ESTABELECIDOS)
# =============================================================================

GRAMMAR_STRATEGIES = {
    "systematic": "explicacao_sistematica",
    "l1_prevention": "prevencao_erros_l1"
}

CEFR_LEVELS = ["A1", "A2", "B1", "B2", "C1", "C2"]

LANGUAGE_VARIANTS = ["american", "british", "australian", "canadian"]


@dataclass
class GrammarContent:
    """Estrutura do conte√∫do gramatical gerado."""
    grammar_point: str
    explanation: str
    examples: List[str]
    patterns: List[str]
    strategy_type: str
    variant_notes: Optional[str] = None
    l1_interference_focus: Optional[Dict[str, Any]] = None


class GrammarRequest(BaseModel):
    """Modelo de requisi√ß√£o para gera√ß√£o de gram√°tica - Pydantic 2."""
    input_text: str = Field(..., description="Texto base para an√°lise gramatical")
    vocabulary_list: List[str] = Field(..., description="Lista de vocabul√°rio dispon√≠vel") 
    level: str = Field(..., description="N√≠vel CEFR (A1, A2, B1, B2, C1, C2)")
    variant: str = Field(default="american", description="Variante do ingl√™s")
    unit_context: str = Field(default="", description="Contexto espec√≠fico da unidade")
    strategy: str = Field(default="systematic", description="Estrat√©gia: systematic ou l1_prevention")
    rag_context: Dict[str, Any] = Field(default_factory=dict, description="Contexto RAG da hierarquia")

    # üî• Pydantic 2 - Nova sintaxe de configura√ß√£o
    model_config = ConfigDict(
        str_strip_whitespace=True,
        validate_assignment=True,
        arbitrary_types_allowed=True
    )


class GrammarGenerator:
    """Gerador de conte√∫do gramatical contextual - LangChain 0.3 + IA."""
    
    def __init__(self):
        """Inicializar gerador com LangChain 0.3 e IA contextual."""
        self.llm = None
        self._load_config()
        
    def _load_config(self):
        """Carregar configura√ß√µes para LangChain 0.3."""
        try:
            # Configura√ß√£o do modelo
            openai_config = get_openai_config()
            model_configs = load_model_configs()
            
            # Configurar ChatOpenAI para v0.3
            grammar_config = openai_config.get("content_configs", {}).get("gramatica_generation", {})
            
            # üîß Par√¢metros para LangChain 0.3
            self.llm = ChatOpenAI(
                model=openai_config.get("model", "gpt-4o-mini"),
                max_tokens=grammar_config.get("max_tokens", 3072), 
                temperature=grammar_config.get("temperature", 0.3),  # Mais baixa para consist√™ncia
                timeout=openai_config.get("timeout", 60),
                max_retries=openai_config.get("max_retries", 3),
                api_key=openai_config.get("api_key")
            )
            
            logger.info(f"‚úÖ ChatOpenAI v0.3 configurado com IA contextual: {openai_config.get('model')}")
                
        except Exception as e:
            logger.error(f"‚ùå Erro na configura√ß√£o: {e}")
            raise

    async def generate_grammar_content(self, request: GrammarRequest) -> GrammarContent:
        """
        Gerar conte√∫do gramatical contextual - LangChain 0.3 + IA.
        
        Args:
            request: Dados da requisi√ß√£o validados pelo Pydantic 2
            
        Returns:
            GrammarContent: Conte√∫do estruturado por estrat√©gia
        """
        try:
            logger.info(f"üéØ Gerando gram√°tica {request.level} - Estrat√©gia: {request.strategy}")
            
            # Valida√ß√£o autom√°tica pelo Pydantic 2
            if not request.input_text.strip():
                raise ValueError("Texto de entrada vazio")
            
            # AN√ÅLISE VIA IA: Identificar ponto gramatical principal
            grammar_point = await self._identify_grammar_point_ai(
                text=request.input_text,
                vocabulary=request.vocabulary_list,
                context=request.unit_context,
                level=request.level
            )
            
            # AN√ÅLISE VIA IA: Gerar prompt contextual baseado na estrat√©gia
            contextual_messages = await self._generate_contextual_prompt_ai(
                request=request,
                grammar_point=grammar_point
            )
            
            # üöÄ LangChain 0.3 - M√©todo ainvoke moderno
            logger.debug("üîÑ Invocando LLM com prompt contextual (LangChain 0.3)")
            response = await self.llm.ainvoke(contextual_messages)
            
            # Extrair conte√∫do da resposta
            content = response.content if hasattr(response, 'content') else str(response)
            
            # AN√ÅLISE VIA IA: Parser inteligente da resposta
            grammar_content = await self._parse_grammar_response_ai(
                content=content, 
                request=request,
                grammar_point=grammar_point
            )
            
            logger.info(f"‚úÖ Gram√°tica gerada: {grammar_point} ({request.strategy})")
            return grammar_content
            
        except ValidationError as e:
            logger.error(f"‚ùå Erro Pydantic 2: {e}")
            raise
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o: {e}")
            raise

    # =============================================================================
    # AN√ÅLISES VIA IA (SUBSTITUEM PROMPTS HARD-CODED)
    # =============================================================================

    async def _identify_grammar_point_ai(
        self, 
        text: str, 
        vocabulary: List[str], 
        context: str, 
        level: str
    ) -> str:
        """Identificar ponto gramatical principal via an√°lise IA."""
        
        system_prompt = """Voc√™ √© um especialista em an√°lise gramatical contextual.
        
        Identifique o ponto gramatical mais relevante e produtivo considerando o texto, vocabul√°rio e contexto espec√≠ficos."""
        
        human_prompt = f"""Identifique o ponto gramatical principal:
        
        TEXTO: {text}
        VOCABUL√ÅRIO: {', '.join(vocabulary[:10])}
        CONTEXTO DA UNIDADE: {context}
        N√çVEL CEFR: {level}
        
        Analise e determine qual ponto gramatical seria mais relevante e pedagogicamente produtivo para esta situa√ß√£o espec√≠fica.
        
        Considere:
        - Estruturas presentes no texto
        - Vocabul√°rio dispon√≠vel para exemplos
        - Adequa√ß√£o ao n√≠vel {level}
        - Relev√¢ncia para o contexto "{context}"
        
        Retorne APENAS o nome do ponto gramatical (ex: "Present Perfect", "Modal Verbs", "Conditional Sentences")."""
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            grammar_point = response.content.strip()
            
            # Valida√ß√£o b√°sica
            if len(grammar_point) > 100:
                grammar_point = grammar_point[:100]
            
            return grammar_point if grammar_point else "Grammar Structures"
            
        except Exception as e:
            logger.warning(f"Erro na identifica√ß√£o gramatical via IA: {str(e)}")
            return "Grammar Structures"

    async def _generate_contextual_prompt_ai(
        self, 
        request: GrammarRequest, 
        grammar_point: str
    ) -> List[Any]:
        """Gerar prompt contextual espec√≠fico via IA baseado na estrat√©gia."""
        
        # Determinar tipo de estrat√©gia
        if request.strategy == "l1_prevention":
            return await self._generate_l1_prevention_prompt(request, grammar_point)
        else:
            return await self._generate_systematic_prompt(request, grammar_point)

    async def _generate_systematic_prompt(
        self, 
        request: GrammarRequest, 
        grammar_point: str
    ) -> List[Any]:
        """Gerar prompt para GRAMMAR 1: Explica√ß√£o Sistem√°tica."""
        
        # AN√ÅLISE VIA IA: Abordagem sistem√°tica espec√≠fica
        systematic_approach = await self._analyze_systematic_approach_ai(
            grammar_point=grammar_point,
            level=request.level,
            context=request.unit_context,
            vocabulary=request.vocabulary_list
        )
        
        system_prompt = f"""Voc√™ √© um especialista em ensino sistem√°tico de gram√°tica inglesa.
        
        Sua tarefa √© criar explica√ß√£o sistem√°tica e estruturada do ponto gramatical, adaptada ao contexto espec√≠fico.
        
        ESTRAT√âGIA: GRAMMAR 1 - Explica√ß√£o Sistem√°tica
        ABORDAGEM CONTEXTUAL: {systematic_approach}"""
        
        human_prompt = f"""Crie explica√ß√£o sistem√°tica para:
        
        PONTO GRAMATICAL: {grammar_point}
        TEXTO BASE: {request.input_text}
        VOCABUL√ÅRIO: {', '.join(request.vocabulary_list[:10])}
        N√çVEL: {request.level}
        CONTEXTO: {request.unit_context}
        VARIANTE: {request.variant}
        
        FORMATO ESTRUTURADO:
        1. EXPLICA√á√ÉO CLARA: Regra gramatical adaptada ao n√≠vel {request.level}
        2. ESTRUTURA/PADR√ÉO: Como formar e usar
        3. EXEMPLOS CONTEXTUAIS: 4-5 exemplos usando o vocabul√°rio dispon√≠vel
        4. PADR√ïES DE USO: Quando e como aplicar
        5. NOTAS VARIANTE: Diferen√ßas {request.variant} se relevante
        
        Mantenha foco pedag√≥gico sistem√°tico e use vocabul√°rio dispon√≠vel nos exemplos."""
        
        return [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]

    async def _generate_l1_prevention_prompt(
        self, 
        request: GrammarRequest, 
        grammar_point: str
    ) -> List[Any]:
        """Gerar prompt para GRAMMAR 2: Preven√ß√£o L1‚ÜíL2."""
        
        # AN√ÅLISE VIA IA: Padr√µes de interfer√™ncia L1
        l1_analysis = await self._analyze_l1_interference_ai(
            grammar_point=grammar_point,
            context=request.unit_context,
            vocabulary=request.vocabulary_list,
            level=request.level
        )
        
        system_prompt = f"""Voc√™ √© um especialista em interfer√™ncia lingu√≠stica portugu√™s‚Üíingl√™s.
        
        Sua tarefa √© focar na preven√ß√£o de erros espec√≠ficos que brasileiros cometem com este ponto gramatical.
        
        ESTRAT√âGIA: GRAMMAR 2 - Preven√ß√£o de Erros L1‚ÜíL2
        AN√ÅLISE L1: {l1_analysis}"""
        
        human_prompt = f"""Crie conte√∫do focado em preven√ß√£o L1‚ÜíL2:
        
        PONTO GRAMATICAL: {grammar_point}
        TEXTO BASE: {request.input_text}
        VOCABUL√ÅRIO: {', '.join(request.vocabulary_list[:10])}
        N√çVEL: {request.level}
        CONTEXTO: {request.unit_context}
        
        FOCO EM INTERFER√äNCIA PORTUGU√äS‚ÜíINGL√äS:
        1. ERRO COMUM: Principal erro que brasileiros cometem
        2. PADR√ÉO PORTUGU√äS: Como seria em portugu√™s
        3. FORMA INCORRETA: Como brasileiros falam/escrevem erroneamente
        4. FORMA CORRETA: Como deve ser em ingl√™s
        5. EXEMPLOS CONTRASTIVOS: Portugu√™s vs Ingl√™s correto
        6. ESTRAT√âGIAS DE PREVEN√á√ÉO: Como evitar o erro
        
        Use vocabul√°rio dispon√≠vel e contexto "{request.unit_context}" nos exemplos."""
        
        return [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]

    async def _analyze_systematic_approach_ai(
        self, 
        grammar_point: str, 
        level: str, 
        context: str, 
        vocabulary: List[str]
    ) -> str:
        """An√°lise via IA da melhor abordagem sistem√°tica."""
        
        system_prompt = """Voc√™ √© um especialista em metodologia de ensino de gram√°tica.
        
        Determine a melhor abordagem sistem√°tica para ensinar este ponto gramatical considerando o contexto espec√≠fico."""
        
        human_prompt = f"""Determine abordagem sistem√°tica para:
        
        PONTO GRAMATICAL: {grammar_point}
        N√çVEL: {level}
        CONTEXTO: {context}
        VOCABUL√ÅRIO DISPON√çVEL: {', '.join(vocabulary[:8])}
        
        Recomende a abordagem pedag√≥gica mais eficaz:
        - Sequ√™ncia de apresenta√ß√£o
        - Foco principal para este n√≠vel
        - Como usar o vocabul√°rio dispon√≠vel
        - Progress√£o l√≥gica de conceitos
        
        Retorne estrat√©gia sistem√°tica espec√≠fica para este contexto."""
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            return response.content.strip()
            
        except Exception as e:
            logger.warning(f"Erro na an√°lise sistem√°tica via IA: {str(e)}")
            return f"Abordagem sistem√°tica adaptada para {level} no contexto {context}"

    async def _analyze_l1_interference_ai(
        self, 
        grammar_point: str, 
        context: str, 
        vocabulary: List[str], 
        level: str
    ) -> str:
        """An√°lise via IA de padr√µes de interfer√™ncia L1 (portugu√™s‚Üíingl√™s)."""
        
        system_prompt = """Voc√™ √© um especialista em interfer√™ncia lingu√≠stica portugu√™s-ingl√™s.
        
        Analise os principais erros que brasileiros cometem com este ponto gramatical espec√≠fico."""
        
        human_prompt = f"""Analise interfer√™ncia L1‚ÜíL2 para:
        
        PONTO GRAMATICAL: {grammar_point}
        CONTEXTO: {context}
        VOCABUL√ÅRIO: {', '.join(vocabulary[:8])}
        N√çVEL: {level}
        
        Identifique:
        - Principal erro que brasileiros cometem com {grammar_point}
        - Por que este erro acontece (influ√™ncia do portugu√™s)
        - Padr√µes espec√≠ficos de interfer√™ncia neste contexto
        - Exemplos t√≠picos de erro portugu√™s‚Üíingl√™s
        
        Foque nos erros mais comuns para {level} no contexto "{context}".
        
        Retorne an√°lise espec√≠fica de interfer√™ncia L1."""
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            return response.content.strip()
            
        except Exception as e:
            logger.warning(f"Erro na an√°lise L1 via IA: {str(e)}")
            return f"An√°lise de interfer√™ncia L1 para {grammar_point} no contexto {context}"

    async def _parse_grammar_response_ai(
        self, 
        content: str, 
        request: GrammarRequest,
        grammar_point: str
    ) -> GrammarContent:
        """Parser inteligente via IA para estruturar resposta."""
        
        system_prompt = """Voc√™ √© um especialista em estrutura√ß√£o de conte√∫do educacional.
        
        Extraia e organize as informa√ß√µes da resposta em categorias estruturadas."""
        
        human_prompt = f"""Estruture este conte√∫do gramatical:
        
        CONTE√öDO: {content}
        ESTRAT√âGIA: {request.strategy}
        PONTO GRAMATICAL: {grammar_point}
        
        Extraia e organize em formato JSON:
        {{
            "explanation": "explica√ß√£o principal clara",
            "examples": ["exemplo 1", "exemplo 2", "exemplo 3"],
            "patterns": ["padr√£o 1", "padr√£o 2"],
            "variant_notes": "notas sobre variante se houver",
            "l1_focus": "aspectos de interfer√™ncia L1 se aplic√°vel"
        }}
        
        Mantenha foco na estrat√©gia {request.strategy}."""
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            
            # Tentar parsear JSON
            try:
                if "```json" in response.content:
                    json_content = response.content.split("```json")[1].split("```")[0].strip()
                else:
                    json_content = response.content
                
                parsed_data = json.loads(json_content)
                
                return GrammarContent(
                    grammar_point=grammar_point,
                    explanation=parsed_data.get("explanation", "Explica√ß√£o via IA"),
                    examples=parsed_data.get("examples", []),
                    patterns=parsed_data.get("patterns", []),
                    strategy_type=GRAMMAR_STRATEGIES.get(request.strategy, request.strategy),
                    variant_notes=parsed_data.get("variant_notes"),
                    l1_interference_focus={"focus": parsed_data.get("l1_focus")} if parsed_data.get("l1_focus") else None
                )
                
            except (json.JSONDecodeError, KeyError):
                logger.warning("Erro no parsing JSON, usando parser t√©cnico fallback")
                return self._technical_parser_fallback(content, request, grammar_point)
                
        except Exception as e:
            logger.warning(f"Erro no parser IA: {str(e)}")
            return self._technical_parser_fallback(content, request, grammar_point)

    # =============================================================================
    # PARSER T√âCNICO (MANTIDO - UTILIT√ÅRIO T√âCNICO)
    # =============================================================================

    def _technical_parser_fallback(
        self, 
        content: str, 
        request: GrammarRequest, 
        grammar_point: str
    ) -> GrammarContent:
        """Parser t√©cnico fallback quando IA parsing falha."""
        
        lines = [line.strip() for line in content.split('\n') if line.strip()]
        
        # Inicializar campos
        explanation = ""
        examples = []
        patterns = []
        variant_notes = None
        l1_interference_focus = None
        
        current_section = None
        
        # Parsing contextual t√©cnico
        for line in lines:
            line_lower = line.lower()
            
            # Detectar se√ß√µes por palavras-chave t√©cnicas
            if any(kw in line_lower for kw in ["explica√ß√£o", "explanation", "regra"]):
                current_section = "explanation"
                if ":" in line:
                    explanation += line.split(":", 1)[-1].strip() + " "
                    
            elif any(kw in line_lower for kw in ["exemplos", "examples"]):
                current_section = "examples"
                
            elif any(kw in line_lower for kw in ["padr√µes", "patterns", "uso"]):
                current_section = "patterns"
                
            elif any(kw in line_lower for kw in ["variante", "variant", "diferen√ßas"]):
                current_section = "variant"
                
            elif any(kw in line_lower for kw in ["erro", "interfer√™ncia", "l1", "portugu√™s"]):
                current_section = "l1"
                
            else:
                # Adicionar conte√∫do √† se√ß√£o atual (l√≥gica t√©cnica)
                if current_section == "explanation":
                    explanation += line + " "
                elif current_section == "examples":
                    if line.startswith(("‚Ä¢", "-", "1.", "2.", "3.", "*")) or len(line) > 20:
                        examples.append(line.lstrip("‚Ä¢-123456789.*‚Ä¢ "))
                elif current_section == "patterns":
                    if line.startswith(("‚Ä¢", "-", "1.", "2.", "3.", "*")):
                        patterns.append(line.lstrip("‚Ä¢-123456789.*‚Ä¢ "))
                elif current_section == "variant":
                    variant_notes = (variant_notes or "") + line + " "
                elif current_section == "l1":
                    l1_interference_focus = {"focus": line}
        
        # Fallbacks t√©cnicos
        if not explanation:
            explanation = content[:300].strip()
        if not examples:
            sentences = [s.strip() for s in content.replace('\n', ' ').split('.') 
                        if 15 < len(s.strip()) < 100]
            examples = sentences[:3] if sentences else ["Exemplo contextual"]
        if not patterns:
            patterns = ["Padr√£o gramatical identificado"]
        
        return GrammarContent(
            grammar_point=grammar_point,
            explanation=explanation.strip(),
            examples=examples[:5],
            patterns=patterns[:3],
            strategy_type=GRAMMAR_STRATEGIES.get(request.strategy, request.strategy),
            variant_notes=variant_notes.strip() if variant_notes else None,
            l1_interference_focus=l1_interference_focus
        )

    # =============================================================================
    # UTILIT√ÅRIOS T√âCNICOS (MANTIDOS)
    # =============================================================================

    def format_for_output(self, grammar_content: GrammarContent) -> Dict[str, Any]:
        """Formatar para sa√≠da estruturada (utilit√°rio t√©cnico)."""
        return {
            "type": "grammar",
            "grammar_point": grammar_content.grammar_point,
            "explanation": grammar_content.explanation,
            "examples": grammar_content.examples,
            "patterns": grammar_content.patterns,
            "strategy_type": grammar_content.strategy_type,
            "variant_notes": grammar_content.variant_notes,
            "l1_interference_focus": grammar_content.l1_interference_focus,
            "metadata": {
                "generated_at": "timestamp",
                "section": "grammar",
                "langchain_version": "0.3.x",
                "pydantic_version": "2.x",
                "ai_contextual": True
            }
        }

    async def get_service_status(self) -> Dict[str, Any]:
        """Status do servi√ßo (utilit√°rio t√©cnico)."""
        return {
            "service": "GrammarGenerator",
            "status": "active",
            "strategies": list(GRAMMAR_STRATEGIES.values()),
            "ai_integration": "100% contextual analysis",
            "langchain_version": "0.3.x",
            "supported_levels": CEFR_LEVELS,
            "supported_variants": LANGUAGE_VARIANTS,
            "ai_methods": [
                "_identify_grammar_point_ai",
                "_analyze_systematic_approach_ai",
                "_analyze_l1_interference_ai", 
                "_parse_grammar_response_ai"
            ]
        }


# üöÄ Fun√ß√£o utilit√°ria moderna (MANTIDA - INTERFACE T√âCNICA)
async def generate_grammar(
    text: str, 
    vocabulary: List[str], 
    level: str = "B1", 
    variant: str = "american",
    unit_context: str = "",
    strategy: str = "systematic"
) -> Dict[str, Any]:
    """
    Fun√ß√£o simplificada para gerar gram√°tica com LangChain 0.3 + IA contextual.
    
    Args:
        text: Texto base
        vocabulary: Lista de vocabul√°rio
        level: N√≠vel CEFR
        variant: Variante do ingl√™s
        unit_context: Contexto espec√≠fico da unidade
        strategy: "systematic" ou "l1_prevention"
        
    Returns:
        Dict: Conte√∫do gramatical formatado
    """
    generator = GrammarGenerator()
    
    # Pydantic 2 - valida√ß√£o autom√°tica
    request = GrammarRequest(
        input_text=text,
        vocabulary_list=vocabulary,
        level=level,
        variant=variant,
        unit_context=unit_context,
        strategy=strategy
    )
    
    grammar_content = await generator.generate_grammar_content(request)
    return generator.format_for_output(grammar_content)

# =============================================================================
# GRAMMAR GENERATOR SERVICE - CLASSE FALTANTE
# =============================================================================

class GrammarGeneratorService:
    """
    Service wrapper para GrammarGenerator - compatibilidade com sistema IVO V2.
    Esta classe fornece interface compat√≠vel esperada pelo sistema.
    """
    
    def __init__(self):
        """Inicializar service com generator interno."""
        self.generator = GrammarGenerator()
        logger.info("‚úÖ GrammarGeneratorService inicializado")
    
    async def generate_grammar_content(
        self, 
        request: GrammarRequest
    ) -> GrammarContent:
        """
        Interface principal para gera√ß√£o de gram√°tica.
        
        Args:
            request: Dados da requisi√ß√£o validados pelo Pydantic 2
            
        Returns:
            GrammarContent: Conte√∫do estruturado por estrat√©gia
        """
        return await self.generator.generate_grammar_content(request)
    
    async def generate_grammar_for_unit(
        self,
        unit_data: Dict[str, Any],
        vocabulary_items: List[str],
        context: str = "",
        strategy: str = "systematic"
    ) -> Dict[str, Any]:
        """
        Gerar gram√°tica para uma unidade espec√≠fica.
        Interface compat√≠vel com sistema hier√°rquico IVO V2.
        
        Args:
            unit_data: Dados da unidade
            vocabulary_items: Vocabul√°rio da unidade
            context: Contexto da unidade
            strategy: Estrat√©gia gramatical
            
        Returns:
            Dict: Conte√∫do gramatical formatado para unidade
        """
        try:
            # Extrair informa√ß√µes da unidade
            level = unit_data.get("cefr_level", "B1")
            variant = unit_data.get("language_variant", "american_english").replace("_english", "")
            unit_context = context or unit_data.get("context", "")
            
            # Texto base da unidade
            text_sources = []
            if unit_data.get("main_aim"):
                text_sources.append(unit_data["main_aim"])
            if unit_data.get("subsidiary_aims"):
                text_sources.extend(unit_data["subsidiary_aims"])
            if unit_context:
                text_sources.append(unit_context)
            
            input_text = ". ".join(text_sources) or "Grammar practice with available vocabulary."
            
            # Criar request
            request = GrammarRequest(
                input_text=input_text,
                vocabulary_list=vocabulary_items,
                level=level,
                variant=variant,
                unit_context=unit_context,
                strategy=strategy
            )
            
            # Gerar conte√∫do
            grammar_content = await self.generator.generate_grammar_content(request)
            
            # Formatar para sa√≠da do sistema
            formatted_content = self.generator.format_for_output(grammar_content)
            
            # Adicionar metadados espec√≠ficos da unidade
            formatted_content["unit_integration"] = {
                "unit_id": unit_data.get("id"),
                "vocabulary_used": vocabulary_items[:10],
                "context_applied": unit_context,
                "strategy_applied": strategy,
                "level_targeted": level
            }
            
            logger.info(f"‚úÖ Gram√°tica gerada para unidade: {grammar_content.grammar_point}")
            return formatted_content
            
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o de gram√°tica para unidade: {str(e)}")
            raise
    
    def get_available_strategies(self) -> List[str]:
        """Retornar estrat√©gias dispon√≠veis."""
        return list(GRAMMAR_STRATEGIES.keys())
    
    async def get_service_status(self) -> Dict[str, Any]:
        """Status do service."""
        generator_status = await self.generator.get_service_status()
        return {
            **generator_status,
            "service_name": "GrammarGeneratorService",
            "wrapper_status": "active",
            "ivo_v2_compatible": True
        }
    
    async def validate_grammar_request(self, request_data: Dict[str, Any]) -> bool:
        """Validar dados de requisi√ß√£o."""
        try:
            GrammarRequest(**request_data)
            return True
        except ValidationError:
            return False


# =============================================================================
# INST√ÇNCIA GLOBAL PARA COMPATIBILIDADE
# =============================================================================

# Inst√¢ncia global que ser√° importada pelo sistema
grammar_service = GrammarGeneratorService()


# =============================================================================
# FUN√á√ÉO DE CONVENI√äNCIA PARA INTEGRA√á√ÉO
# =============================================================================

async def create_grammar_for_unit(
    unit_data: Dict[str, Any],
    vocabulary_items: List[str] = None,
    context: str = "",
    strategy: str = "systematic"
) -> Dict[str, Any]:
    """
    Fun√ß√£o de conveni√™ncia para integra√ß√£o com sistema IVO V2.
    
    Args:
        unit_data: Dados completos da unidade
        vocabulary_items: Lista de vocabul√°rio (opcional)
        context: Contexto adicional
        strategy: "systematic" ou "l1_prevention"
        
    Returns:
        Dict: Conte√∫do gramatical pronto para uso
    """
    service = GrammarGeneratorService()
    
    # Usar vocabul√°rio da unidade se n√£o fornecido
    if vocabulary_items is None:
        vocabulary_section = unit_data.get("vocabulary", {})
        if isinstance(vocabulary_section, dict):
            items = vocabulary_section.get("items", [])
            vocabulary_items = [item.get("word", "") for item in items if isinstance(item, dict)]
        else:
            vocabulary_items = []
    
    return await service.generate_grammar_for_unit(
        unit_data=unit_data,
        vocabulary_items=vocabulary_items,
        context=context,
        strategy=strategy
    )

# Exemplo e teste para LangChain 0.3 + IA Contextual
if __name__ == "__main__":
    async def test_langchain_v03_ai():
        """Testar LangChain 0.3 + IA contextual."""
        try:
            print("üß™ Testando LangChain 0.3 + IA Contextual...")
            
            # Testar GRAMMAR 1: Sistem√°tica
            result1 = await generate_grammar(
                text="The students have been learning English for two years.",
                vocabulary=["learn", "student", "year", "English", "study"],
                level="B2",
                variant="american",
                unit_context="academic environment",
                strategy="systematic"
            )
            
            print("üéØ GRAMMAR 1 (Sistem√°tica):")
            print(f"   Ponto: {result1['grammar_point']}")
            print(f"   Estrat√©gia: {result1['strategy_type']}")
            
            # Testar GRAMMAR 2: L1 Prevention
            result2 = await generate_grammar(
                text="I am working here since 2020.",
                vocabulary=["work", "since", "here", "year"],
                level="A2", 
                variant="american",
                unit_context="workplace",
                strategy="l1_prevention"
            )
            
            print("üéØ GRAMMAR 2 (L1 Prevention):")
            print(f"   Ponto: {result2['grammar_point']}")
            print(f"   Estrat√©gia: {result2['strategy_type']}")
            print(f"   L1 Focus: {result2['l1_interference_focus']}")
            
            print("üéâ LangChain 0.3 + IA Contextual funcionando!")
            
        except Exception as e:
            print(f"‚ùå Erro no teste: {e}")
    
    # Executar teste
    asyncio.run(test_langchain_v03_ai())